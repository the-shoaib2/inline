[
    {
        "id": "codegemma:2b",
        "name": "CodeGemma 2B",
        "size": 1717986918,
        "description": "Fast and efficient model for Python/JavaScript",
        "languages": [
            "python",
            "javascript",
            "typescript"
        ],
        "requirements": {
            "vram": 2,
            "ram": 4,
            "cpu": true,
            "gpu": false
        },
        "isDownloaded": false,
        "architecture": "gemma",
        "contextWindow": 8192,
        "fimTemplate": "codegemma"
    },
    {
        "id": "codegemma:7b",
        "name": "CodeGemma 7B",
        "size": 7516192768,
        "description": "Balanced performance for multiple languages",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go"
        ],
        "requirements": {
            "vram": 8,
            "ram": 12,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "gemma",
        "contextWindow": 8192,
        "fimTemplate": "codegemma"
    },
    {
        "id": "stablecode:3b",
        "name": "StableCode 3B",
        "size": 3221225472,
        "description": "Multi-language support with good performance",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "cpp",
            "java",
            "go"
        ],
        "requirements": {
            "vram": 4,
            "ram": 6,
            "cpu": true,
            "gpu": false
        },
        "isDownloaded": false,
        "architecture": "stablelm",
        "contextWindow": 16384,
        "fimTemplate": "stable-code"
    },
    {
        "id": "deepseek-coder:1.3b",
        "name": "DeepSeek Coder 1.3B",
        "size": 1395864371,
        "description": "Ultra-lightweight model for basic completions",
        "languages": [
            "python",
            "javascript",
            "typescript"
        ],
        "requirements": {
            "vram": 2,
            "ram": 3,
            "cpu": true,
            "gpu": false
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 16384,
        "fimTemplate": "deepseek"
    },
    {
        "id": "deepseek-coder:6.7b",
        "name": "DeepSeek Coder 6.7B",
        "size": 7194070220,
        "description": "Excellent for complex patterns and scientific computing",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "cpp",
            "java",
            "go",
            "rust"
        ],
        "requirements": {
            "vram": 8,
            "ram": 12,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 16384,
        "fimTemplate": "deepseek"
    },
    {
        "id": "deepseek-coder:33b",
        "name": "DeepSeek Coder 33B",
        "size": 35433480192,
        "description": "Large model for enterprise-grade code generation",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "cpp",
            "java",
            "go",
            "rust",
            "php",
            "ruby",
            "swift",
            "kotlin"
        ],
        "requirements": {
            "vram": 24,
            "ram": 32,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 16384,
        "fimTemplate": "deepseek"
    },
    {
        "id": "starcoder2:3b",
        "name": "StarCoder2 3B",
        "size": 3221225472,
        "description": "Efficient model for quick completions",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp"
        ],
        "requirements": {
            "vram": 4,
            "ram": 6,
            "cpu": true,
            "gpu": false
        },
        "isDownloaded": false,
        "architecture": "starcoder2",
        "contextWindow": 16384,
        "fimTemplate": "starcoder"
    },
    {
        "id": "starcoder2:7b",
        "name": "StarCoder2 7B",
        "size": 7516192768,
        "description": "Strong across multiple programming languages",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "cpp",
            "java",
            "go",
            "rust",
            "php"
        ],
        "requirements": {
            "vram": 8,
            "ram": 12,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "starcoder2",
        "contextWindow": 16384,
        "fimTemplate": "starcoder"
    },
    {
        "id": "starcoder2:15b",
        "name": "StarCoder2 15B",
        "size": 16106127360,
        "description": "Advanced model for complex code patterns",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "cpp",
            "java",
            "go",
            "rust",
            "php",
            "ruby",
            "swift"
        ],
        "requirements": {
            "vram": 16,
            "ram": 24,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "starcoder2",
        "contextWindow": 16384,
        "fimTemplate": "starcoder"
    },
    {
        "id": "codellama:7b",
        "name": "CodeLlama 7B",
        "size": 7516192768,
        "description": "Meta's proven model for enterprise patterns",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "cpp",
            "java",
            "go"
        ],
        "requirements": {
            "vram": 8,
            "ram": 12,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 16384,
        "fimTemplate": "codellama"
    },
    {
        "id": "codellama:13b",
        "name": "CodeLlama 13B",
        "size": 13958643712,
        "description": "Enhanced CodeLlama for better accuracy",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "cpp",
            "java",
            "go",
            "rust",
            "php"
        ],
        "requirements": {
            "vram": 16,
            "ram": 20,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 16384,
        "fimTemplate": "codellama"
    },
    {
        "id": "codellama:34b",
        "name": "CodeLlama 34B",
        "size": 36507222016,
        "description": "Large-scale model for complex codebases",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "cpp",
            "java",
            "go",
            "rust",
            "php",
            "ruby",
            "swift",
            "kotlin"
        ],
        "requirements": {
            "vram": 24,
            "ram": 32,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 16384,
        "fimTemplate": "codellama"
    },
    {
        "id": "codellama:70b",
        "name": "CodeLlama 70B",
        "size": 75161927680,
        "description": "Flagship model for maximum accuracy",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "cpp",
            "java",
            "go",
            "rust",
            "php",
            "ruby",
            "swift",
            "kotlin",
            "csharp",
            "scala"
        ],
        "requirements": {
            "vram": 48,
            "ram": 64,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 16384,
        "fimTemplate": "codellama"
    },
    {
        "id": "phi:2.7b",
        "name": "Phi 2.7B",
        "size": 2899102720,
        "description": "Microsoft's efficient small model",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "cpp",
            "java"
        ],
        "requirements": {
            "vram": 4,
            "ram": 6,
            "cpu": true,
            "gpu": false
        },
        "isDownloaded": false,
        "architecture": "phi",
        "contextWindow": 2048,
        "fimTemplate": "phi"
    },
    {
        "id": "phi3:3.8b",
        "name": "Phi-3 Mini 3.8B",
        "size": 4080218931,
        "description": "Latest Phi model with improved performance",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "cpp",
            "java",
            "go"
        ],
        "requirements": {
            "vram": 5,
            "ram": 8,
            "cpu": true,
            "gpu": false
        },
        "isDownloaded": false,
        "architecture": "phi",
        "contextWindow": 4096,
        "fimTemplate": "phi"
    },
    {
        "id": "phi3:14b",
        "name": "Phi-3 Medium 14B",
        "size": 15032385536,
        "description": "Balanced Phi-3 for production use",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "cpp",
            "java",
            "go",
            "rust",
            "php"
        ],
        "requirements": {
            "vram": 16,
            "ram": 20,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "phi",
        "contextWindow": 8192,
        "fimTemplate": "phi"
    },
    {
        "id": "wizardcoder:7b",
        "name": "WizardCoder 7B",
        "size": 7516192768,
        "description": "Fine-tuned for instruction following",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp"
        ],
        "requirements": {
            "vram": 8,
            "ram": 12,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 16384,
        "fimTemplate": "wizardcoder"
    },
    {
        "id": "wizardcoder:13b",
        "name": "WizardCoder 13B",
        "size": 13958643712,
        "description": "Enhanced instruction-following capabilities",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go",
            "rust"
        ],
        "requirements": {
            "vram": 16,
            "ram": 20,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 16384,
        "fimTemplate": "wizardcoder"
    },
    {
        "id": "wizardcoder:34b",
        "name": "WizardCoder 34B",
        "size": 36507222016,
        "description": "Large instruction-tuned model",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go",
            "rust",
            "php",
            "ruby"
        ],
        "requirements": {
            "vram": 24,
            "ram": 32,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 16384,
        "fimTemplate": "wizardcoder"
    },
    {
        "id": "mistral:7b",
        "name": "Mistral 7B",
        "size": 7516192768,
        "description": "General-purpose model with code capabilities",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go"
        ],
        "requirements": {
            "vram": 8,
            "ram": 12,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "mistral",
        "contextWindow": 8192,
        "fimTemplate": "mistral"
    },
    {
        "id": "mixtral:8x7b",
        "name": "Mixtral 8x7B",
        "size": 60129542144,
        "description": "Mixture of experts for diverse tasks",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go",
            "rust",
            "php",
            "ruby",
            "swift"
        ],
        "requirements": {
            "vram": 40,
            "ram": 48,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "mixtral",
        "contextWindow": 32768,
        "fimTemplate": "mixtral"
    },
    {
        "id": "qwen:7b",
        "name": "Qwen 7B",
        "size": 7516192768,
        "description": "Alibaba's multilingual code model",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go"
        ],
        "requirements": {
            "vram": 8,
            "ram": 12,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "qwen",
        "contextWindow": 8192,
        "fimTemplate": "qwen"
    },
    {
        "id": "qwen:14b",
        "name": "Qwen 14B",
        "size": 15032385536,
        "description": "Enhanced Qwen for better code understanding",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go",
            "rust",
            "php"
        ],
        "requirements": {
            "vram": 16,
            "ram": 20,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "qwen",
        "contextWindow": 8192,
        "fimTemplate": "qwen"
    },
    {
        "id": "qwen:72b",
        "name": "Qwen 72B",
        "size": 77309411328,
        "description": "Large-scale multilingual model",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go",
            "rust",
            "php",
            "ruby",
            "swift",
            "kotlin",
            "csharp"
        ],
        "requirements": {
            "vram": 48,
            "ram": 64,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "qwen",
        "contextWindow": 32768,
        "fimTemplate": "qwen"
    },
    {
        "id": "yi-coder:1.5b",
        "name": "Yi Coder 1.5B",
        "size": 1610612736,
        "description": "Tiny model for resource-constrained environments",
        "languages": [
            "python",
            "javascript",
            "typescript"
        ],
        "requirements": {
            "vram": 2,
            "ram": 3,
            "cpu": true,
            "gpu": false
        },
        "isDownloaded": false,
        "architecture": "yi",
        "contextWindow": 4096,
        "fimTemplate": "yi"
    },
    {
        "id": "yi-coder:6b",
        "name": "Yi Coder 6B",
        "size": 6442450944,
        "description": "Efficient Chinese-English bilingual model",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go"
        ],
        "requirements": {
            "vram": 8,
            "ram": 10,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "yi",
        "contextWindow": 8192,
        "fimTemplate": "yi"
    },
    {
        "id": "yi-coder:9b",
        "name": "Yi Coder 9B",
        "size": 9663676416,
        "description": "Advanced bilingual code generation",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go",
            "rust"
        ],
        "requirements": {
            "vram": 12,
            "ram": 16,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "yi",
        "contextWindow": 8192,
        "fimTemplate": "yi"
    },
    {
        "id": "granite-code:3b",
        "name": "Granite Code 3B",
        "size": 3221225472,
        "description": "IBM's enterprise-focused code model",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp"
        ],
        "requirements": {
            "vram": 4,
            "ram": 6,
            "cpu": true,
            "gpu": false
        },
        "isDownloaded": false,
        "architecture": "granite",
        "contextWindow": 8192,
        "fimTemplate": "granite"
    },
    {
        "id": "granite-code:8b",
        "name": "Granite Code 8B",
        "size": 8589934592,
        "description": "Enterprise-grade code generation",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go",
            "rust"
        ],
        "requirements": {
            "vram": 10,
            "ram": 14,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "granite",
        "contextWindow": 8192,
        "fimTemplate": "granite"
    },
    {
        "id": "granite-code:20b",
        "name": "Granite Code 20B",
        "size": 21474836480,
        "description": "Large enterprise model for complex tasks",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go",
            "rust",
            "php",
            "ruby"
        ],
        "requirements": {
            "vram": 20,
            "ram": 28,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "granite",
        "contextWindow": 8192,
        "fimTemplate": "granite"
    },
    {
        "id": "llama3:8b",
        "name": "Llama 3 8B",
        "size": 8589934592,
        "description": "Meta's latest general-purpose model",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go"
        ],
        "requirements": {
            "vram": 10,
            "ram": 14,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 8192,
        "fimTemplate": "llama3"
    },
    {
        "id": "llama3:70b",
        "name": "Llama 3 70B",
        "size": 75161927680,
        "description": "Large-scale Llama 3 for advanced tasks",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go",
            "rust",
            "php",
            "ruby",
            "swift",
            "kotlin"
        ],
        "requirements": {
            "vram": 48,
            "ram": 64,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 8192,
        "fimTemplate": "llama3"
    },
    {
        "id": "solar:10.7b",
        "name": "Solar 10.7B",
        "size": 11490762752,
        "description": "Upstage's efficient model",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go"
        ],
        "requirements": {
            "vram": 12,
            "ram": 16,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "solar",
        "contextWindow": 4096,
        "fimTemplate": "solar"
    },
    {
        "id": "openchat:7b",
        "name": "OpenChat 7B",
        "size": 7516192768,
        "description": "Conversational code assistant",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp"
        ],
        "requirements": {
            "vram": 8,
            "ram": 12,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "openchat",
        "contextWindow": 8192,
        "fimTemplate": "openchat"
    },
    {
        "id": "orca2:7b",
        "name": "Orca 2 7B",
        "size": 7516192768,
        "description": "Microsoft's reasoning-focused model",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp"
        ],
        "requirements": {
            "vram": 8,
            "ram": 12,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "orca",
        "contextWindow": 4096,
        "fimTemplate": "orca"
    },
    {
        "id": "orca2:13b",
        "name": "Orca 2 13B",
        "size": 13958643712,
        "description": "Enhanced reasoning capabilities",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go",
            "rust"
        ],
        "requirements": {
            "vram": 16,
            "ram": 20,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "orca",
        "contextWindow": 4096,
        "fimTemplate": "orca"
    },
    {
        "id": "vicuna:7b",
        "name": "Vicuna 7B",
        "size": 7516192768,
        "description": "Fine-tuned LLaMA for conversations",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java"
        ],
        "requirements": {
            "vram": 8,
            "ram": 12,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 2048,
        "fimTemplate": "vicuna"
    },
    {
        "id": "vicuna:13b",
        "name": "Vicuna 13B",
        "size": 13958643712,
        "description": "Larger conversational model",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go"
        ],
        "requirements": {
            "vram": 16,
            "ram": 20,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 2048,
        "fimTemplate": "vicuna"
    },
    {
        "id": "nous-hermes2:10.7b",
        "name": "Nous Hermes 2 10.7B",
        "size": 11490762752,
        "description": "Fine-tuned for instruction following",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go"
        ],
        "requirements": {
            "vram": 12,
            "ram": 16,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "nous",
        "contextWindow": 4096,
        "fimTemplate": "nous"
    },
    {
        "id": "dolphin-coder:7b",
        "name": "Dolphin Coder 7B",
        "size": 7516192768,
        "description": "Uncensored code generation model",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp"
        ],
        "requirements": {
            "vram": 8,
            "ram": 12,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 16384,
        "fimTemplate": "dolphin"
    },
    {
        "id": "dolphin-coder:15b",
        "name": "Dolphin Coder 15B",
        "size": 16106127360,
        "description": "Advanced uncensored coding assistant",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp",
            "go",
            "rust",
            "php"
        ],
        "requirements": {
            "vram": 16,
            "ram": 24,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 16384,
        "fimTemplate": "dolphin"
    },
    {
        "id": "magicoder:7b",
        "name": "MagiCoder 7B",
        "size": 7516192768,
        "description": "OSS-Instruct trained model",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp"
        ],
        "requirements": {
            "vram": 8,
            "ram": 12,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 16384,
        "fimTemplate": "magicoder"
    },
    {
        "id": "sqlcoder:7b",
        "name": "SQLCoder 7B",
        "size": 7516192768,
        "description": "Specialized for SQL generation",
        "languages": [
            "sql",
            "python",
            "javascript"
        ],
        "requirements": {
            "vram": 8,
            "ram": 12,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 8192,
        "fimTemplate": "sqlcoder"
    },
    {
        "id": "sqlcoder:15b",
        "name": "SQLCoder 15B",
        "size": 16106127360,
        "description": "Advanced SQL and database queries",
        "languages": [
            "sql",
            "python",
            "javascript",
            "java"
        ],
        "requirements": {
            "vram": 16,
            "ram": 24,
            "cpu": false,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 8192,
        "fimTemplate": "sqlcoder"
    },
    {
        "id": "tinyllama:1.1b",
        "name": "TinyLlama 1.1B",
        "size": 1181116006,
        "description": "Ultra-compact model for basic tasks",
        "languages": [
            "python",
            "javascript"
        ],
        "requirements": {
            "vram": 1,
            "ram": 2,
            "cpu": true,
            "gpu": false
        },
        "isDownloaded": false,
        "architecture": "llama",
        "contextWindow": 2048,
        "fimTemplate": "tinyllama"
    },
    {
        "id": "openhermes:7b",
        "name": "OpenHermes 7B",
        "size": 7516192768,
        "description": "Versatile assistant model",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp"
        ],
        "requirements": {
            "vram": 8,
            "ram": 12,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "mistral",
        "contextWindow": 8192,
        "fimTemplate": "openhermes"
    },
    {
        "id": "zephyr:7b",
        "name": "Zephyr 7B",
        "size": 7516192768,
        "description": "Aligned for helpful responses",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java"
        ],
        "requirements": {
            "vram": 8,
            "ram": 12,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "mistral",
        "contextWindow": 8192,
        "fimTemplate": "zephyr"
    },
    {
        "id": "neural-chat:7b",
        "name": "Neural Chat 7B",
        "size": 7516192768,
        "description": "Intel's optimized chat model",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java",
            "cpp"
        ],
        "requirements": {
            "vram": 8,
            "ram": 12,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "mistral",
        "contextWindow": 8192,
        "fimTemplate": "neural"
    },
    {
        "id": "starling:7b",
        "name": "Starling 7B",
        "size": 7516192768,
        "description": "RLAIF trained for helpfulness",
        "languages": [
            "python",
            "javascript",
            "typescript",
            "java"
        ],
        "requirements": {
            "vram": 8,
            "ram": 12,
            "cpu": true,
            "gpu": true
        },
        "isDownloaded": false,
        "architecture": "openchat",
        "contextWindow": 8192,
        "fimTemplate": "starling"
    }
]